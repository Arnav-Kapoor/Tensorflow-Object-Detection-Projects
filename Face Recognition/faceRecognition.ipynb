{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "41401028-3fae-4229-a26d-88f9681106b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a61fe3b-1722-4101-a273-950edc312eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aeb529-f1e3-4bb8-b4d7-5cea64422e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python --upgrade\n",
    "# !pip uninstall opencv-python-headless -y "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43f44f9-3266-492a-be3a-3690758933e1",
   "metadata": {},
   "source": [
    "### getting the dataset ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d89a991-ee70-408f-a2bb-a7d32c0105db",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xf lfw.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d16b5196-4307-4991-bde4-87f12ab85bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH=os.path.join('data','images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b3e2ee-dadd-4cd3-a198-2e8a2f088b0f",
   "metadata": {},
   "source": [
    "#### negative images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27205f2-8246-4b1e-8251-84d25b9f8764",
   "metadata": {},
   "outputs": [],
   "source": [
    "for directories in os.listdir('lfw'):\n",
    "    for files in os.listdir(os.path.join('lfw',directories)):\n",
    "        OLD_PATH=os.path.join('lfw',directories,files)\n",
    "        NEW_PATH=os.path.join(IMG_PATH,files)\n",
    "        os.replace(OLD_PATH,NEW_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106bba03-2c50-4f26-9841-8865ba194768",
   "metadata": {},
   "source": [
    "#### user image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0316ff54-53d9-4a18-a698-4ae458d7e81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PATH=os.path.join(\"data\",\"user\",\"face\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa65368c-d320-4e33-8d43-3a69032a0ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## capturing image\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret,frame=cap.read()\n",
    "    frame=frame[50:50+250,210:210+250]\n",
    "    if cv2.waitKey(1) & 0xFF==ord('c'):\n",
    "        imgname=os.path.join(USER_PATH,\"user_face.jpg\")\n",
    "        cv2.imwrite(imgname,frame)\n",
    "        break\n",
    "    cv2.imshow(\"frame\",frame)\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e381f0-fb2b-4ed1-a556-a4ac317efd80",
   "metadata": {},
   "source": [
    "#### augment the image for positives and anchor images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8f2ad9-264a-4675-9d59-4a7a4ed570f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b3a0c62-f8e1-4648-87b4-e035f7e681d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUG_PATH=os.path.join(\"data\",\"user\",\"aug_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91677bb3-b3e7-48ba-a6f9-e4ead7cbe619",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folders in os.listdir(AUG_PATH):\n",
    "    for i in range(30):\n",
    "        img=cv2.imread(os.path.join(USER_PATH,\"user_face.jpg\"))\n",
    "        imgname=os.path.join(AUG_PATH,folders,str(uuid.uuid1())+\".jpg\")\n",
    "\n",
    "        img = tf.image.stateless_random_brightness(img, max_delta=0.02, seed=(1,2))\n",
    "        img = tf.image.stateless_random_contrast(img, lower=0.6, upper=1, seed=(1,3))\n",
    "        img = tf.image.stateless_random_flip_up_down(img,seed=(np.random.randint(100),np.random.randint(100)))\n",
    "        img = tf.image.stateless_random_flip_left_right(img, seed=(np.random.randint(100),np.random.randint(100)))\n",
    "        img = tf.image.stateless_random_jpeg_quality(img, min_jpeg_quality=90, max_jpeg_quality=100, seed=(np.random.randint(100),np.random.randint(100)))\n",
    "        img = tf.image.stateless_random_saturation(img, lower=0.9, upper=1, seed=(np.random.randint(100),np.random.randint(100))) \n",
    "\n",
    "        cv2.imwrite(imgname,img.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cdfe4e-1c28-412d-8644-8b7fd5c87208",
   "metadata": {},
   "source": [
    "### loading images in tf data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "444427f3-fb2d-4ef2-867e-0c47f5f5f509",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive=tf.data.Dataset.list_files(os.path.join(AUG_PATH+\"/positive/*.jpg\"),shuffle=False)\n",
    "anchor=tf.data.Dataset.list_files(os.path.join(AUG_PATH+\"/anchor/*.jpg\"),shuffle=False)\n",
    "negative=tf.data.Dataset.list_files(os.path.join(IMG_PATH+\"/*.jpg\"),shuffle=False).take(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78c94c5f-1574-4829-8e0b-58c7facbc83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(x):\n",
    "    byte_image=tf.io.read_file(x)\n",
    "    img=tf.io.decode_jpeg(byte_image)\n",
    "    img=tf.image.resize(img,(100,100))\n",
    "    img=img/255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f940b76-fbbb-4947-96e4-a787128f11d5",
   "metadata": {},
   "source": [
    "### labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "deede1e4-44c4-4dd2-8461-53fd854d8437",
   "metadata": {},
   "outputs": [],
   "source": [
    "positives=tf.data.Dataset.zip((anchor,positive,tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negatives=tf.data.Dataset.zip((anchor,negative,tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "data=positives.concatenate(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a329866c-f087-491e-9d08-152b1610cce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4729a7e8-ebe5-429f-af24-3377be681e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example=sample.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f60e869-aef4-45be-95b5-28805add3369",
   "metadata": {},
   "outputs": [],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3da6e222-2cc9-491f-942d-0accfa030705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(input_image,val_image,label):\n",
    "    return (load_image(input_image),load_image(val_image),label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883881d8-1ef6-489f-ad35-97e5aad776b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "res=preprocess(*example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451f8ab4-5352-4904-8021-a598053fa91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(res[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fc24b-1123-43a1-a229-9a0e9567fc8a",
   "metadata": {},
   "source": [
    "### Train and Test partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf6e234b-e04a-4ecd-b62d-64e539bf914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build data loader pipeline\n",
    "data=data.map(preprocess)\n",
    "data=data.cache()\n",
    "data=data.shuffle(buffer_size=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db29ce01-8471-4a6d-9c19-693cb5242473",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fbdf929-25e7-4fa2-a300-6fce81350fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=data.take(round(len(data)*.7))\n",
    "train_data=train_data.batch(8)\n",
    "train_data=train_data.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86198b93-eae3-46b5-9ef5-ea3df86c5b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b96c7ca9-c907-4ae8-b155-cbadc5eb01c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=data.skip(round(len(data)*.7))\n",
    "test_data=test_data.take(round(len(data)*.3))\n",
    "test_data=test_data.batch(8)\n",
    "test_data=test_data.prefetch(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f89d0e-01ee-4e9f-9fa9-6b98f5f9a30c",
   "metadata": {},
   "source": [
    "### building feature extractor(embedding layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "428c4400-ee9e-4972-95fb-a16a0f79f1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer,Input,Conv2D,Dense,MaxPooling2D,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dd03928-cfd9-47b7-b1cb-4422ad9b41ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor():\n",
    "    inp=Input(shape=(100,100,3),name=\"input_image\")\n",
    "    \n",
    "    c1=Conv2D(64,(10,10),activation=\"relu\")(inp)\n",
    "    m1=MaxPooling2D(64,(2,2),padding=\"same\")(c1)\n",
    "    \n",
    "    c2=Conv2D(128,(7,7),activation=\"relu\")(m1)\n",
    "    m2=MaxPooling2D(64,(2,2),padding=\"same\")(c2)\n",
    "    \n",
    "    c3=Conv2D(128,(4,4),activation=\"relu\")(m2)\n",
    "    m3=MaxPooling2D(64,(2,2),padding=\"same\")(c3)\n",
    "    \n",
    "    c4=Conv2D(256,(4,4),activation=\"relu\")(m3)\n",
    "    f1=Flatten()(c4)\n",
    "    d1=Dense(4096,activation=\"sigmoid\")(f1)\n",
    "    \n",
    "    return Model(inputs=[inp],outputs=[d1],name=\"feature_extractor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28d6c527-4d28-4c3c-84c7-96c9c4cd7068",
   "metadata": {},
   "outputs": [],
   "source": [
    "featExt=feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca603b5f-9852-442b-a3c6-68680a685d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"feature_extractor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_image (InputLayer)    [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 91, 91, 64)        19264     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 46, 46, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 40, 40, 128)       401536    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 20, 20, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 17, 17, 128)       262272    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 9, 9, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 6, 256)         524544    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              37752832  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,960,448\n",
      "Trainable params: 38,960,448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "featExt.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6edc84-fd88-4d2e-ae52-92997329b614",
   "metadata": {},
   "source": [
    "### build distance layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d56e2d5-4ebc-4757-97c1-8fe921186fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1Dist(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "    def call(self,input_embedding,val_embedding):\n",
    "        return(tf.math.abs(input_embedding-val_embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa9e65f-e97f-4d8a-87d2-d9dba5cf461b",
   "metadata": {},
   "source": [
    "### siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d57bdc03-46f1-452f-a6d6-b3d61c0ebbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def siamese_model():\n",
    "    input_image=Input(shape=(100,100,3),name=\"input_image\")\n",
    "    val_image=Input(shape=(100,100,3),name=\"val_image\")\n",
    "    \n",
    "    siamese_layer=L1Dist()\n",
    "    siamese_layer._name=\"l1_dist_layer\"\n",
    "    \n",
    "    distance=siamese_layer(featExt(input_image),featExt(val_image))\n",
    "    \n",
    "    classifier=Dense(1,activation=\"sigmoid\")(distance)\n",
    "    \n",
    "    return Model(inputs=[input_image,val_image],outputs=classifier,name=\"SiameseNetwork\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee6f2315-5251-4693-9595-f366d8a0d4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm=siamese_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2cdd65-307a-4ccc-a994-179281fa3505",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45f44a9-7c4d-4328-93e9-73f09b4ac9ed",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "991d2eaf-a181-4529-883f-8c49a866f85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cross_entropy=tf.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd4153a8-a0d6-4674-9b6c-a75f617be21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "712a5859-8318-4764-b120-a362005fe389",
   "metadata": {},
   "outputs": [],
   "source": [
    "##checkpoints\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model=sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6d7449-678e-4243-affd-9726cb60a8ff",
   "metadata": {},
   "source": [
    "#### train step funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd2db0e5-80c2-49ab-b992-44fdeb5db654",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch=train_data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec94a8e5-9054-4b26-ba6c-1ee9f1b84acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1=test_batch.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9e3017-1ba2-401b-a0b6-519c19116d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "862f831d-ad83-499d-b403-4ad062eae3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=batch_1[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b941f998-4cff-41a2-840b-ccf0c661a54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=batch_1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab51c46-27eb-48ac-b872-af664a9ae198",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e31f379c-a683-4873-92a5-ab8f2ea0be8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        X=batch[:2]\n",
    "        y=batch[2] \n",
    "        \n",
    "        yhat=sm(X,training=True)\n",
    "        loss=binary_cross_entropy(y,yhat)\n",
    "    print(loss)\n",
    "    grad=tape.gradient(loss,sm.trainable_variables)\n",
    "        \n",
    "    opt.apply_gradients(zip(grad,sm.trainable_variables))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72d9867-d508-472b-9f5c-d2e0a9ef3a67",
   "metadata": {},
   "source": [
    "#### training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c32d4b5-66db-44c7-9dc9-024766cefb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Recall,Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bd242c0-c719-4485-a507-6acc001675bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data,EPOCHS):\n",
    "    for epoch in range(1,EPOCHS+1):\n",
    "        print(\"\\n Epoch {}/{}\".format(epoch,EPOCHS))\n",
    "        progbar=tf.keras.utils.Progbar(len(data))\n",
    "        \n",
    "        r=Recall()\n",
    "        p=Precision()\n",
    "        \n",
    "        for idx,batch in enumerate(data):\n",
    "            loss=train_step(batch)\n",
    "            yhat=sm.predict(batch[:2])\n",
    "            r.update_state(yhat,batch[2])\n",
    "            p.update_state(yhat,batch[2])\n",
    "            progbar.update(idx+1)\n",
    "        print(loss.numpy(),r.result().numpy(),p.result().numpy())\n",
    "        \n",
    "        if epoch % 10 == 0: \n",
    "            checkpoint.save(file_prefix=checkpoint_prefix) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565d424a-69d4-4650-867f-d42f1a6f336f",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cdfc377c-4959-4bb6-9419-33695f038964",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "181227cd-34fa-4840-961d-643627b846de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1/15\n",
      "tf.Tensor(0.69599676, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 836ms/step\n",
      "1/6 [====>.........................] - ETA: 2:11tf.Tensor(0.68197846, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 648ms/step\n",
      "2/6 [=========>....................] - ETA: 1:00tf.Tensor(0.6327864, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 632ms/step\n",
      "3/6 [==============>...............] - ETA: 44s tf.Tensor(0.5287801, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 682ms/step\n",
      "4/6 [===================>..........] - ETA: 29stf.Tensor(0.48148608, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 650ms/step\n",
      "5/6 [========================>.....] - ETA: 14stf.Tensor(0.2511413, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "6/6 [==============================] - 90s 13s/step\n",
      "0.2511413 0.42857143 1.0\n",
      "\n",
      " Epoch 2/15\n",
      "tf.Tensor(0.26538214, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 640ms/step\n",
      "1/6 [====>.........................] - ETA: 1:13tf.Tensor(0.29411748, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 678ms/step\n",
      "2/6 [=========>....................] - ETA: 58s tf.Tensor(0.42223626, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 656ms/step\n",
      "3/6 [==============>...............] - ETA: 43stf.Tensor(0.47042167, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 651ms/step\n",
      "4/6 [===================>..........] - ETA: 28stf.Tensor(0.37811184, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 732ms/step\n",
      "5/6 [========================>.....] - ETA: 14stf.Tensor(0.7043867, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 596ms/step\n",
      "6/6 [==============================] - 80s 13s/step\n",
      "0.7043867 0.47619048 1.0\n",
      "\n",
      " Epoch 3/15\n",
      "tf.Tensor(0.30543986, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 647ms/step\n",
      "1/6 [====>.........................] - ETA: 1:14tf.Tensor(0.38892922, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 647ms/step\n",
      "2/6 [=========>....................] - ETA: 57s tf.Tensor(0.15132234, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 649ms/step\n",
      "3/6 [==============>...............] - ETA: 43stf.Tensor(0.3171376, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 657ms/step\n",
      "4/6 [===================>..........] - ETA: 29stf.Tensor(0.46616283, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 647ms/step\n",
      "5/6 [========================>.....] - ETA: 14stf.Tensor(0.75959796, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "6/6 [==============================] - 78s 13s/step\n",
      "0.75959796 0.42857143 1.0\n",
      "\n",
      " Epoch 4/15\n",
      "tf.Tensor(0.17815566, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 708ms/step\n",
      "1/6 [====>.........................] - ETA: 1:12tf.Tensor(0.18894732, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 730ms/step\n",
      "2/6 [=========>....................] - ETA: 1:01tf.Tensor(0.35818207, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 932ms/step\n",
      "3/6 [==============>...............] - ETA: 53s tf.Tensor(0.27576494, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 735ms/step\n",
      "4/6 [===================>..........] - ETA: 36stf.Tensor(0.7678771, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 683ms/step\n",
      "5/6 [========================>.....] - ETA: 17stf.Tensor(0.46008325, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "6/6 [==============================] - 90s 15s/step\n",
      "0.46008325 0.45238096 1.0\n",
      "\n",
      " Epoch 5/15\n",
      "tf.Tensor(0.45132747, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 723ms/step\n",
      "1/6 [====>.........................] - ETA: 1:12tf.Tensor(0.54691154, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 657ms/step\n",
      "2/6 [=========>....................] - ETA: 57s tf.Tensor(0.44105995, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 713ms/step\n",
      "3/6 [==============>...............] - ETA: 44stf.Tensor(0.110992126, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 733ms/step\n",
      "4/6 [===================>..........] - ETA: 32stf.Tensor(0.25782433, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 647ms/step\n",
      "5/6 [========================>.....] - ETA: 15stf.Tensor(0.04001529, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "6/6 [==============================] - 82s 14s/step\n",
      "0.04001529 0.47619048 1.0\n",
      "\n",
      " Epoch 6/15\n",
      "tf.Tensor(0.33325195, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 678ms/step\n",
      "1/6 [====>.........................] - ETA: 1:12tf.Tensor(0.23259115, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 722ms/step\n",
      "2/6 [=========>....................] - ETA: 58s tf.Tensor(0.24968085, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3/6 [==============>...............] - ETA: 50stf.Tensor(0.32328343, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4/6 [===================>..........] - ETA: 36stf.Tensor(0.404614, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "5/6 [========================>.....] - ETA: 19stf.Tensor(0.6499585, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 0s 409ms/step\n",
      "6/6 [==============================] - 98s 17s/step\n",
      "0.6499585 0.52380955 1.0\n",
      "\n",
      " Epoch 7/15\n",
      "tf.Tensor(0.37050128, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 932ms/step\n",
      "1/6 [====>.........................] - ETA: 1:42tf.Tensor(0.13873288, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 776ms/step\n",
      "2/6 [=========>....................] - ETA: 1:19tf.Tensor(0.2086033, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3/6 [==============>...............] - ETA: 59s tf.Tensor(0.3521999, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4/6 [===================>..........] - ETA: 42stf.Tensor(0.26249123, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "5/6 [========================>.....] - ETA: 21stf.Tensor(0.20428587, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 0s 462ms/step\n",
      "6/6 [==============================] - 111s 18s/step\n",
      "0.20428587 0.5714286 1.0\n",
      "\n",
      " Epoch 8/15\n",
      "tf.Tensor(0.3342268, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/6 [====>.........................] - ETA: 1:41tf.Tensor(0.16421373, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2/6 [=========>....................] - ETA: 1:22tf.Tensor(0.09393042, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 871ms/step\n",
      "3/6 [==============>...............] - ETA: 57s tf.Tensor(0.15798537, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 941ms/step\n",
      "4/6 [===================>..........] - ETA: 37stf.Tensor(0.16279674, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "5/6 [========================>.....] - ETA: 19stf.Tensor(0.122401506, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 0s 424ms/step\n",
      "6/6 [==============================] - 106s 17s/step\n",
      "0.122401506 0.52380955 1.0\n",
      "\n",
      " Epoch 9/15\n",
      "tf.Tensor(0.19204217, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/6 [====>.........................] - ETA: 1:42tf.Tensor(0.18617995, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2/6 [=========>....................] - ETA: 1:21tf.Tensor(0.05890757, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3/6 [==============>...............] - ETA: 1:01tf.Tensor(0.014438821, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4/6 [===================>..........] - ETA: 40s tf.Tensor(0.11975623, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "5/6 [========================>.....] - ETA: 20stf.Tensor(0.35093343, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 0s 487ms/step\n",
      "6/6 [==============================] - 109s 18s/step\n",
      "0.35093343 0.5 1.0\n",
      "\n",
      " Epoch 10/15\n",
      "tf.Tensor(0.09841654, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/6 [====>.........................] - ETA: 1:41tf.Tensor(0.03605763, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2/6 [=========>....................] - ETA: 1:20tf.Tensor(0.21471131, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3/6 [==============>...............] - ETA: 1:01tf.Tensor(0.10828239, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4/6 [===================>..........] - ETA: 41s tf.Tensor(0.11182928, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "5/6 [========================>.....] - ETA: 20stf.Tensor(0.33739057, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 508ms/step\n",
      "6/6 [==============================] - 109s 18s/step\n",
      "0.33739057 0.52380955 1.0\n",
      "\n",
      " Epoch 11/15\n",
      "tf.Tensor(0.1260909, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/6 [====>.........................] - ETA: 1:29tf.Tensor(0.09538241, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2/6 [=========>....................] - ETA: 1:25tf.Tensor(0.09220993, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3/6 [==============>...............] - ETA: 1:03tf.Tensor(0.0062988717, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4/6 [===================>..........] - ETA: 42s tf.Tensor(0.005054552, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "5/6 [========================>.....] - ETA: 21stf.Tensor(0.011377583, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 933ms/step\n",
      "6/6 [==============================] - 111s 19s/step\n",
      "0.011377583 0.47619048 1.0\n",
      "\n",
      " Epoch 12/15\n",
      "tf.Tensor(0.24971385, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/6 [====>.........................] - ETA: 1:53tf.Tensor(0.08379007, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2/6 [=========>....................] - ETA: 1:23tf.Tensor(0.004856228, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3/6 [==============>...............] - ETA: 1:02tf.Tensor(0.091702, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4/6 [===================>..........] - ETA: 41s tf.Tensor(0.006859629, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "5/6 [========================>.....] - ETA: 21stf.Tensor(0.010270826, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 0s 452ms/step\n",
      "6/6 [==============================] - 113s 18s/step\n",
      "0.010270826 0.54761904 1.0\n",
      "\n",
      " Epoch 13/15\n",
      "tf.Tensor(0.078758165, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/6 [====>.........................] - ETA: 1:45tf.Tensor(0.07952774, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2/6 [=========>....................] - ETA: 1:23tf.Tensor(0.14136052, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3/6 [==============>...............] - ETA: 1:01tf.Tensor(0.08596132, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4/6 [===================>..........] - ETA: 41s tf.Tensor(0.08749447, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "5/6 [========================>.....] - ETA: 20stf.Tensor(0.0016942669, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 0s 488ms/step\n",
      "6/6 [==============================] - 110s 18s/step\n",
      "0.0016942669 0.5 1.0\n",
      "\n",
      " Epoch 14/15\n",
      "tf.Tensor(0.084815465, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/6 [====>.........................] - ETA: 1:41tf.Tensor(0.08578355, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2/6 [=========>....................] - ETA: 1:22tf.Tensor(0.077029586, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "3/6 [==============>...............] - ETA: 1:02tf.Tensor(0.0010765252, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4/6 [===================>..........] - ETA: 41s tf.Tensor(0.1347559, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "5/6 [========================>.....] - ETA: 20stf.Tensor(0.2110717, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 540ms/step\n",
      "6/6 [==============================] - 110s 18s/step\n",
      "0.2110717 0.47619048 1.0\n",
      "\n",
      " Epoch 15/15\n",
      "tf.Tensor(0.17476192, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/6 [====>.........................] - ETA: 1:42tf.Tensor(0.06948157, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2/6 [=========>....................] - ETA: 1:22tf.Tensor(0.05302371, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 861ms/step\n",
      "3/6 [==============>...............] - ETA: 59s tf.Tensor(0.08207628, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "4/6 [===================>..........] - ETA: 39stf.Tensor(0.08660614, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "5/6 [========================>.....] - ETA: 19stf.Tensor(0.00078682747, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 1s 524ms/step\n",
      "6/6 [==============================] - 108s 17s/step\n",
      "0.00078682747 0.47619048 1.0\n"
     ]
    }
   ],
   "source": [
    "train(train_data,EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7623f48f-09ae-4ff7-8299-385d755d502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input, test_val, y_true = test_data.as_numpy_iterator().next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853a6ff2-cf35-4873-a35b-60591fe67e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = sm.predict([test_input, test_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35416c54-bd5d-4c27-b85f-adbd53afd0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "[1 if prediction > 0.5 else 0 for prediction in y_hat ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7c62ca-7185-45c7-87ef-6eb639fc18c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3d07f1-bf6d-4467-acae-57c38249476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_val[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aced320-fbc7-437e-a09b-2b2cfbe2b166",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7420e7b-e676-4759-bdac-22272b89738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cafd8155-ba0e-4f6c-94c9-2398335023fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "sm.save(\"siameseModel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3be188-ab25-4cf5-8cf3-52ad1b0d3f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm=load_model(\"siameseModel.h5\",custom_objects={\"L1Dist\":L1Dist,\"binary_cross_entropy\":binary_cross_entropy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4887a04c-ff63-4d10-bf26-5192e21b94a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.compile(optimizer=tf.keras.optimizers.Adam(1e-4),loss=binary_cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeb3836-9d59-4c1f-9611-27096c47f9f9",
   "metadata": {},
   "source": [
    "### Realtime Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba05d9c7-91d1-4026-b3f4-6f181577b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5a291b-e912-47fa-804b-3f0d06a08911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(user_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0a234e-d816-4e40-becd-eae4d0fdda7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img=cv2.imread(\"./data/user/val.jpeg\")\n",
    "# img=tf.image.resize(img,(100,100))\n",
    "# img=img/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eb1a39-6b54-4c6d-890a-005db16b4d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm.predict(list(np.expand_dims([img, user_img], axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2c5bd4-9787-4ee8-bb37-25036898d2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## capturing image\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret,frame=cap.read()\n",
    "    frame=frame[50:50+250,210:210+250]\n",
    "   \n",
    "    if cv2.waitKey(1) & 0xFF==ord('c'):\n",
    "        print(\"processing...\")\n",
    "        imgname=os.path.join(USER_PATH,\"user_face.jpg\")\n",
    "        cv2.imwrite(imgname,frame)\n",
    "        break\n",
    "            \n",
    "    cv2.imshow(\"frame\",frame)\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06736063-8123-4936-8220-4e8511df917f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch=(list(np.expand_dims([user_img],axis=1)),list(np.expand_dims([user_img],axis=1)),np.asarray(1).astype('float32').reshape((-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c45b9df-5eef-4f77-ae83-61d3f6c8e798",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4efd4b3-5d17-4a2f-8ecd-e8094ecfb3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_img=cv2.imread(os.path.join(USER_PATH,\"user_face.jpg\"))\n",
    "user_img=tf.image.resize(user_img,(100,100))\n",
    "user_img=user_img/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da73c36-14b0-49a8-8ba4-a27680e69841",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret,frame=cap.read()\n",
    "    frame=frame[50:50+250,210:210+250,:]\n",
    "    \n",
    "    try:\n",
    "        if cv2.waitKey(1) & 0xFF==ord('v'):\n",
    "            print(\"verifying\")\n",
    "            img=tf.image.resize(frame,(100,100))\n",
    "            img=img/255.0\n",
    "            results=sm.predict(list(np.expand_dims([img, user_img], axis=1)),verbose=False)\n",
    "            print(results)\n",
    "            \n",
    "            if results>0.5:\n",
    "                print(\"Access Granted!\")\n",
    "            else:\n",
    "                print(\"Access Denied\")\n",
    "        # print(img.shape)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "            \n",
    "    cv2.imshow(\"frame\",frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8202878f-e748-48a1-8327-73ebe5ac59b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
